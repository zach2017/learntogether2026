FROM nvcr.io/nvidia/cuda:12.1.1-cudnn8-devel-ubuntu22.04

ENV DEBIAN_FRONTEND=noninteractive
RUN apt-get update && apt-get install -y git python3 python3-pip build-essential cmake libopenblas-dev pkg-config wget

RUN pip install torch --index-url https://download.pytorch.org/whl/cu121
RUN pip install -U "transformers>=4.37.0" "datasets>=2.16.0" "accelerate>=0.26.1" "peft>=0.7.1" "bitsandbytes>=0.41.3" "trl>=0.7.10" "safetensors>=0.4.1" "optimum>=1.16.2" "huggingface_hub>=0.20.3" "ninja" packaging flash-attn

RUN git clone https://github.com/OpenAccess-AI-Collective/axolotl /axolotl && cd /axolotl && pip install -e '.[flash-attn,deepspeed]'

RUN git clone https://github.com/ggerganov/llama.cpp /llama.cpp && cd /llama.cpp && make -j

WORKDIR /workspace
CMD ["bash"]